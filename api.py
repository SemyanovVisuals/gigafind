import io
from typing import Union, Annotated

import uvicorn
from PIL import Image
from pydantic import BaseModel
from fastapi import FastAPI, File, UploadFile, Form, Response

from scripts.llm_req import get_llm_text
from scripts.seq_lib import inference
from scripts.types import PointRequest

app = FastAPI()


def extract_images_from_bytes(frames: list[bytes]):
    """
    Extract images from bytes by the device data

    :param image_bytes: the bytes containing the pictures
    :return:
    """
    images = []
    for frame in frames:
        print(len(frame), type(frame))
        image = Image.open(io.BytesIO(frame))
        images.append(image)

    return images


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.post("/boxes",  # Set what the media type will be in the autogenerated OpenAPI specification.
          # fastapi.tiangolo.com/advanced/additional-responses/#additional-media-types-for-the-main-response
          response_class=Response)
def read_item(frames: Annotated[list[bytes], File()], box_batch_str: Annotated[str, Form()]):
    print("INCOMING REQUEST LEN ", len(frames))
    for file in frames:
        print(type(file))
    coords = [int(coord) for coord in box_batch_str.split(",")]
    boxes = [coords[i:i + 4] for i in range(0, len(coords), 4)]

    for i in range(len(boxes)):
        old_box = boxes[i]
        old_box[1] = max(0, min(960, old_box[1] + 35))
        old_box[3] = max(0, min(960, old_box[3] + 35))
        boxes[i] = old_box

    images = extract_images_from_bytes(frames)
    mask = inference(images, boxes)

    llm_text = get_llm_text(mask)

    response = Response(content=mask, media_type="image/png")
    response.headers["X-LLM-Text"] = llm_text
    return response

    # return {'code': 200}


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
